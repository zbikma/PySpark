{"cells":[{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55261,"status":"ok","timestamp":1724034925098,"user":{"displayName":"Zee Maz","userId":"16682775173566754666"},"user_tz":240},"id":"mi7wntzLe3I1","outputId":"06f5fe12-b9c4-4537-efb8-98ee01181994"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pyspark in ./myenv/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (3.5.2)\n","Collecting findspark (from -r requirements.txt (line 2))\n","  Using cached findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n","Requirement already satisfied: requests in ./myenv/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (2.32.3)\n","Requirement already satisfied: py4j==0.10.9.7 in ./myenv/lib/python3.9/site-packages (from pyspark->-r requirements.txt (line 1)) (0.10.9.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.9/site-packages (from requests->-r requirements.txt (line 3)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.9/site-packages (from requests->-r requirements.txt (line 3)) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.9/site-packages (from requests->-r requirements.txt (line 3)) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.9/site-packages (from requests->-r requirements.txt (line 3)) (2024.7.4)\n","Using cached findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n","Installing collected packages: findspark\n","Successfully installed findspark-2.0.1\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install -r requirements.txt\n"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":135,"status":"ok","timestamp":1724037110715,"user":{"displayName":"Zee Maz","userId":"16682775173566754666"},"user_tz":240},"id":"kdRuhczinYlR"},"outputs":[],"source":["from dotenv import load_dotenv\n","load_dotenv()\n","\n","import os\n","\n","java_home = os.getenv(\"JAVA_HOME\")\n","spark_home = os.getenv(\"SPARK_HOME\")\n","os.environ[\"JAVA_HOME\"]=java_home\n","os.environ[\"SPARK_HOME\"] = spark_home\n","os.environ[\"PATH\"] += os.pathsep + os.path.join(os.environ[\"SPARK_HOME\"], \"bin\")\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":196},"executionInfo":{"elapsed":6944,"status":"ok","timestamp":1724037213149,"user":{"displayName":"Zee Maz","userId":"16682775173566754666"},"user_tz":240},"id":"vtCj7zy_nrYE","outputId":"8840b964-65cb-4038-83c9-c741256593a0"},"outputs":[],"source":["import findspark\n","findspark.init()\n","from pyspark import SparkContext"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["\n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://192.168.2.119:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.5.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>pyspark-shell</code></dd>\n","            </dl>\n","        </div>\n","        "],"text/plain":["<SparkContext master=local[*] appName=pyspark-shell>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["cs = SparkContext.getOrCreate()\n","cs"]},{"cell_type":"markdown","metadata":{},"source":["#Download the dataset"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/LearningUser/Documents/Repos/PySpark/myenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n","  warnings.warn(\n"]},{"data":{"text/plain":["'/Users/LearningUser/Documents/Repos/PySpark'"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","import requests\n","os.getcwd()"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/Users/LearningUser/Documents/Repos/PySpark/myenv/bin/python\n"]}],"source":["import sys\n","print(sys.executable)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["\n","#url= \"https://data.cityofchicago.org/api/views/ijzp-q8t2/rows.csv?accessType=DOWNLOAD\"\n","#response =  requests.get(url)\n","#with open(\"crimes_2001_to_present.csv\",\"wb\") as file:\n","#    file.write(response.content) \n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["import pyspark\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.getOrCreate()"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://192.168.2.119:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.5.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>pyspark-shell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x107680280>"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'DataFrame' object has no attribute 'order'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_timestamp,col,lit\n\u001b[0;32m----> 2\u001b[0m record\u001b[38;5;241m=\u001b[39m\u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcrimes_2001_to_present.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mto_timestamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMM/dd/yyyy hh:mm:ss a\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2018-11-11\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morder\u001b[49m\n\u001b[1;32m      3\u001b[0m record\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m5\u001b[39m)\n","File \u001b[0;32m~/Documents/Repos/PySpark/myenv/lib/python3.9/site-packages/pyspark/sql/dataframe.py:3129\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3096\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   3097\u001b[0m \n\u001b[1;32m   3098\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3126\u001b[0m \u001b[38;5;124;03m+---+\u001b[39;00m\n\u001b[1;32m   3127\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 3129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   3130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name)\n\u001b[1;32m   3131\u001b[0m     )\n\u001b[1;32m   3132\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   3133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n","\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'order'"]}],"source":["from pyspark.sql.functions import to_timestamp,col,lit\n","record=spark.read.csv('crimes_2001_to_present.csv',header=True).withColumn('Date',to_timestamp(col('Date'),'MM/dd/yyyy hh:mm:ss a')).filter(col('Date') <= lit('2018-11-11')).\n","record.show(5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j4_Lx82soBAy"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNWo7sgQf5NCpDOWOUwrZe/","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
